{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity-Based Link Prediction on Yelp Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices, sample\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct full network graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertices = businesses (approximately 27K businesses)\n",
    "\n",
    "Edges = There's an edge between $i$ and $j$ if the number of users are more than xx.\n",
    "\n",
    "Note: See https://networkx.org/documentation/latest/reference/introduction.html#networkx-basics for `nx` package documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine an edge, look at the distribution of `num_users`.\n",
    "\n",
    "Couldn't plot a histogram, probably because it's highly skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = pd.read_feather(\"data/business_edge_user_count.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ZsqqzHu1HHkDdIKoivi5g</td>\n",
       "      <td>1An4DxtMmvvSe0HX4viRCA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ZsqqzHu1HHkDdIKoivi5g</td>\n",
       "      <td>3YqUe2FTCQr0pPVK8oCv6Q</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ZsqqzHu1HHkDdIKoivi5g</td>\n",
       "      <td>3gXgILE2YWVidJDvVWBT6Q</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ZsqqzHu1HHkDdIKoivi5g</td>\n",
       "      <td>HpWi2CRJlxVCYKd8kS0X-A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ZsqqzHu1HHkDdIKoivi5g</td>\n",
       "      <td>KP5OncF2jhT7_J1phHPPww</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       b1                      b2  num_users\n",
       "0  0ZsqqzHu1HHkDdIKoivi5g  1An4DxtMmvvSe0HX4viRCA          4\n",
       "1  0ZsqqzHu1HHkDdIKoivi5g  3YqUe2FTCQr0pPVK8oCv6Q        105\n",
       "2  0ZsqqzHu1HHkDdIKoivi5g  3gXgILE2YWVidJDvVWBT6Q          6\n",
       "3  0ZsqqzHu1HHkDdIKoivi5g  HpWi2CRJlxVCYKd8kS0X-A          4\n",
       "4  0ZsqqzHu1HHkDdIKoivi5g  KP5OncF2jhT7_J1phHPPww         69"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.065332e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.321564e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.913244e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.446000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_users\n",
       "count  2.065332e+07\n",
       "mean   2.321564e+00\n",
       "std    3.913244e+00\n",
       "min    1.000000e+00\n",
       "25%    1.000000e+00\n",
       "50%    1.000000e+00\n",
       "75%    2.000000e+00\n",
       "max    1.446000e+03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(data = edge_df, x = \"num_users\")\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If cutoff = 1, there will be 20653315 edges\n",
      "If cutoff = 5, there will be 1974099 edges\n",
      "If cutoff = 10, there will be 588147 edges\n",
      "If cutoff = 20, there will be 151273 edges\n",
      "If cutoff = 50, there will be 18145 edges\n",
      "If cutoff = 100, there will be 2471 edges\n"
     ]
    }
   ],
   "source": [
    "for cutoff in [1, 5, 10, 20, 50, 100]:\n",
    "    print(f\"If cutoff = {cutoff}, there will be {len(edge_df[edge_df['num_users'] >= cutoff])} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there's about 27K businesses (vertices), probably should take the cutoff = 5 for the existence of an edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5\n",
    "edge_subset = edge_df[edge_df['num_users'] >= cutoff]\n",
    "edge_list = list(zip(*map(edge_subset.get, ['b1', 'b2', 'num_users'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_weighted_edges_from(edge_list) # or use G.add_edges_from(edge_list) for unweifhted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network has degree assortativity: -0.21032761437631706\n"
     ]
    }
   ],
   "source": [
    "deg_assort = nx.degree_assortativity_coefficient(G, x = 'out', y = 'out')\n",
    "print(f\"The network has degree assortativity: {deg_assort}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nx.degree_histogram(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph will be referred to as \"fully observed graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is how we approached train-test split. The process commenced with randomly dividing the existing edges (positive samples) of the graph into training and test sets, allocating 75% to the training set and 25% to the testing set.\n",
    "\n",
    "To enhance the model's predictive power, negative sampling was employed. This involved generating non-existent edges (negative samples) between random pairs of nodes. The key modification here was the efficient generation of these negative edges: instead of checking all possible node pairs, we randomly selected node pairs and verified the absence of an edge between them. The number of negative edges generated matched the number of positive edges in the test set. These negative samples were then divided using the same 75-25 split as the positive samples.\n",
    "\n",
    "The training graph was carefully constructed using only the positive edges from the training set. This step is critical to prevent data leakage and ensures that the training data reflects realistic scenarios for link prediction. The final training and test datasets were then prepared by combining their respective positive and negative edges. This balanced approach in dataset composition is essential for providing a comprehensive and unbiased evaluation of the link prediction model, thereby enhancing its applicability and accuracy in real-world recommender system scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure edge_list is a list of tuples (u, v, weight)\n",
    "edge_list = [(u, v, d['weight']) for u, v, d in G.edges(data=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting positive edges\n",
    "train_edges, test_edges = train_test_split(edge_list, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.5 s, sys: 159 ms, total: 45.6 s\n",
      "Wall time: 45.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# function to generate a single negative edge\n",
    "def generate_neg_edge(G):\n",
    "    nodes_list = list(G.nodes)  # convert nodes to a list\n",
    "    while True:\n",
    "        u, v = sample(nodes_list, 2)\n",
    "        if not G.has_edge(u, v):\n",
    "            return u, v\n",
    "\n",
    "# number of negative edges needed\n",
    "num_neg_edges_needed = len(test_edges)\n",
    "\n",
    "# generate negative edges\n",
    "neg_edges = set()\n",
    "while len(neg_edges) < num_neg_edges_needed:\n",
    "    neg_edges.add(generate_neg_edge(G))\n",
    "\n",
    "# convert to list and sample if necessary\n",
    "neg_edges_sample = list(neg_edges)\n",
    "if len(neg_edges_sample) > num_neg_edges_needed:\n",
    "    neg_edges_sample = sample(neg_edges_sample, num_neg_edges_needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split negative edges into train and test\n",
    "train_neg_edges, test_neg_edges = train_test_split(neg_edges_sample, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new graph for training (useful for feature extraction)\n",
    "g_train = nx.Graph()\n",
    "g_train.add_nodes_from(G.nodes)\n",
    "g_train.add_weighted_edges_from(train_edges)  # Add only training positive edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine positive and negative edges for train and test sets (what we use for actual training and testing)\n",
    "train_set = train_edges + [(u, v, 0) for u, v in train_neg_edges]  # 0 weight for negative edges\n",
    "test_set = test_edges + [(u, v, 0) for u, v in test_neg_edges]  # 0 weight for negative edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute similarity scores with different measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_scores(G, edge_list):\n",
    "    # precompute neighbors for each node\n",
    "    neighbors = {node: set(G.neighbors(node)) for node in G.nodes()}\n",
    "\n",
    "    # precompute Adamic-Adar contributions for each node\n",
    "    adamic_adar_contrib = {node: 1 / np.log(G.degree(node)) if G.degree(node) > 1 else 0 for node in G.nodes()}\n",
    "\n",
    "    common_neighbors = []\n",
    "    jaccard_coefficients = []\n",
    "    adamic_adar_indices = []\n",
    "\n",
    "    # calculate similarity measures\n",
    "    for u, v, _ in tqdm(edge_list):\n",
    "        # Common Neighbors\n",
    "        common_neighbors_count = len(neighbors[u] & neighbors[v])\n",
    "        common_neighbors.append(common_neighbors_count)\n",
    "\n",
    "        # Jaccard Coefficient\n",
    "        union_size = len(neighbors[u] | neighbors[v])\n",
    "        jaccard_coeff = common_neighbors_count / union_size if union_size else 0\n",
    "        jaccard_coefficients.append(jaccard_coeff)\n",
    "\n",
    "        # Adamic-Adar Index\n",
    "        adamic_adar_index = sum(adamic_adar_contrib[w] for w in neighbors[u] & neighbors[v])\n",
    "        adamic_adar_indices.append(adamic_adar_index)\n",
    "\n",
    "    return common_neighbors, jaccard_coefficients, adamic_adar_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 1850717/1850717 [01:57<00:00, 15761.27it/s]\n",
      "100%|██████████████████████████████████████████| 616907/616907 [00:37<00:00, 16374.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 31s, sys: 2.99 s, total: 2min 34s\n",
      "Wall time: 2min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# calculate for train and test sets\n",
    "train_common_neighbors, train_jaccard_coefficients, train_adamic_adar_indices = calculate_similarity_scores(g_train, train_set)\n",
    "test_common_neighbors, test_jaccard_coefficients, test_adamic_adar_indices = calculate_similarity_scores(g_train, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification with link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're trying to predict whether a link should exist between two nodes (AKA how confident... binary classification). Each model is an XGBoost and uses a single similarity measure as its feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train and evaluate a model\n",
    "def train_evaluate_model(train_features, train_labels, test_features, test_labels):\n",
    "    # training the model\n",
    "    model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "    model.fit(train_features, train_labels)\n",
    "\n",
    "    # predicting on the test set\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # evaluating the model\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    precision = precision_score(test_labels, predictions)\n",
    "    recall = recall_score(test_labels, predictions)\n",
    "    f1 = f1_score(test_labels, predictions)\n",
    "    roc_auc = roc_auc_score(test_labels, predictions)\n",
    "\n",
    "    return accuracy, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing labels\n",
    "train_labels = [1 if w > 0 else 0 for _, _, w in train_set]\n",
    "test_labels = [1 if w > 0 else 0 for _, _, w in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:01, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 1.72 s, total: 2min 18s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training and evaluating models for each similarity measure\n",
    "results = []\n",
    "for feature_name, train_feature, test_feature in tqdm(zip(\n",
    "    ['Common Neighbors', 'Jaccard Coefficient', 'Adamic-Adar Index'],\n",
    "    [train_common_neighbors, train_jaccard_coefficients, train_adamic_adar_indices],\n",
    "    [test_common_neighbors, test_jaccard_coefficients, test_adamic_adar_indices]\n",
    ")):\n",
    "    curr_eval = train_evaluate_model(\n",
    "        np.array(train_feature).reshape(-1, 1), train_labels,\n",
    "        np.array(test_feature).reshape(-1, 1), test_labels\n",
    "    )\n",
    "    results.append([feature_name] + list(curr_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity_measure</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Common Neighbors</td>\n",
       "      <td>0.967699</td>\n",
       "      <td>0.971997</td>\n",
       "      <td>0.988090</td>\n",
       "      <td>0.979977</td>\n",
       "      <td>0.937112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaccard Coefficient</td>\n",
       "      <td>0.956963</td>\n",
       "      <td>0.956520</td>\n",
       "      <td>0.991263</td>\n",
       "      <td>0.973581</td>\n",
       "      <td>0.905513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adamic-Adar Index</td>\n",
       "      <td>0.971234</td>\n",
       "      <td>0.974529</td>\n",
       "      <td>0.989915</td>\n",
       "      <td>0.982162</td>\n",
       "      <td>0.943212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    similarity_measure  accuracy  precision    recall        f1   roc_auc\n",
       "0     Common Neighbors  0.967699   0.971997  0.988090  0.979977  0.937112\n",
       "1  Jaccard Coefficient  0.956963   0.956520  0.991263  0.973581  0.905513\n",
       "2    Adamic-Adar Index  0.971234   0.974529  0.989915  0.982162  0.943212"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(results, columns=['similarity_measure', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc'])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to run entire notebook: 0:04:33.146260\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "print(f'Time elapsed to run entire notebook: {t1 - t0}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
